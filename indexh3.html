<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Himanshu Gupta </title>
</head>
<body>
   <b>
    <h1>Backtracking</h1>
   </b> 
    <h2>Copyright Â©2002 by David Matuszek</h2>
    <p>
        Backtracking is a form of recursion.
    </p>
    <p>
        The usual scenario is that you are faced with a number of options, and you must choose one of these. After you make your choice you will get a new set of options; just what set of options you get depends on what choice you made. This procedure is repeated over and over until you reach a final state. If you made a good sequence of choices, your final state is a goal state; if you didn't, it isn'<t class="br"></t>
    </p>
    <p>
        Conceptually, you start at the root of a tree; the tree probably has some good leaves and some bad leaves, though it may be that the leaves are all good or all bad. You want to get to a good leaf. At each node, beginning with the root, you choose one of its children to move to, and you keep this up until you get to a leaf.
    </p>
    <p>
        Suppose you get to a bad leaf. You can backtrack to continue the search for a good leaf by revoking your most recent choice, and trying out the next option in that set of options. If you run out of options, revoke the choice that got you here, and try another choice at that node. If you end up at the root with no options left, there are no good leaves to be found.
    </p>
    <p>
        This needs an example.
    </p>
    <p align="center"><img src="./IMG_20211220_003017.jpg" height="136" width="259" /></p>
    <ol type="1">
    <li>Starting at Root, your options are A and B. You choose A</li>
    <li>At A, your options are C and D. You choose C.</li>
    <li>C is bad. Go back to A.</li>
    <li>At A, you have already tried C, and it failed. Try D.</li>
    <li>D is bad. Go back to A.</li>
    <li>
        At A, you have no options left to try. Go back to Root.</li>
    <li>At Root, you have already tried A. Try B.</li>
    <li>At B, your options are E and F. Try E.</li>
    <p>
        In this example we drew a picture of a tree. The tree is an abstract model 
  of the possible sequences of choices we could make. There is also a data structure 
  called a tree, but usually we don't have a data structure to tell us what choices 
  we have. (If we do have an actual tree data structure, backtracking on it is 
  called 
    </p>
    <p>
    <p>The backtracking algorithm is simple but important. You should understand it 
    thoroughly. Another way of stating it is as follows:</p>
<dir>
  <li>To search a tree: 
    <ol>
      <li> If the tree consists of a single leaf, test whether it is a goal node,</li>
      <li>Otherwise, search the subtrees until you find one containing a goal 
        node, or until you have searched them all unsuccessfully.</li>
    </ol>
  </li>
</dir>
    </p>
    <p>
        
<p><b><font size="+1"><br />
    Keeping backtracking simple</font></b></p>

    </p>
    
<p>All of these versions of the backtracking algorithm are pretty simple, but 
    when applied to a real problem, they can get pretty cluttered up with details. 
    Even determining whether the node is a leaf can be complex: for example, if 
    the path represents a series of moves in a chess endgame problem, the leaves 
    are the checkmate and stalemate solutions. </p>
  <p>To keep the program clean, therefore, tests like this should be buried in methods. 
    In a chess game, for example, you could test whether a node is a leaf by writing 
    a<code> gameOver </code>method (or you could even call it<code> isLeaf</code>). 
    This method would encapsulate all the ugly details of figuring out whether any 
    possible moves remain.</p>
    <p>The most straightforward way to keep track of which children of the node have 
        been tried is as follows: Upon initial entry to the node (that is, when you 
        first get there from above), make a list of all its children. As you try each 
        child, take it off the list. When the list is empty, there are no remaining 
        untried children, and you can return "failure." This is a simple approach, 
        but it may require quite a lot of additional work.
    </p>
    <p>There is an easier way to keep track of which children have been tried, <b>if</b> 
        you can define an ordering on the children. If there is an ordering, and you 
        know which child you just tried, you can determine which child to try next.
    </p>
    <p>A <b>binary tree </b>is a data structure composed of <b>nodes</b>. One node 
        is designated as the <b>root node</b>. Each node can reference (point to) zero, 
        one, or two other nodes, which are called its <b>children</b>. The children 
        are referred to as the <b>left child</b> and/or the <b>right child</b>. All 
        nodes are reachable (by one or more steps) from the root node, and there are 
        no cycles. For our purposes, although this is not part of the definition of 
        a binary tree, we will say that a node might or might not be a goal node, and 
        will contain its name. The first example in this paper (which we repeat here) 
        shows a binary tree.
    </p>
    <p>Here's what the numbered lines are doing:</p>
    <ol>
        <li>If we are given a null node, it's not solvable. This statement is so that 
          we can call this method with the children of a node, without first checking 
          whether those children actually exist.</li>
        <li>If the node we are given is a goal node, return success.</li>
        <li>See if the left child of <code>node</code> is solvable, and if so, conclude 
          that <code>node</code> is solvable. We will only get to this line if <code>node</code> 
          is non-null and is not a goal node, says to </li>
        <li>Do the same thing for the right child.</li>
        <li>Since neither child of <code>node</code> is solvable, <code>node</code> 
          itself is not solvable.</li>
      </ol>
      <p>This program runs correctly and produces the unenlightening result <code>true</code>.</p>
      <p> Each time we ask for another node, we have to check if it is <code>null</code>. 
        In the above we put that check as the first thing in <code>solvable</code>. 
        An alternative would be to check first whether each child exists, and recur 
        only if they do. Here's that alternative version: </p>
        <p>I think the first version is simpler, but the second version is slightly more 
            efficient. </p>
          <p><b><font size="+1"><br />
            What are the children?</font></b></p>
          <p>One of the things that simplifies the above binary tree search is that, at 
            each choice point, you can ignore all the previous choices. Previous choices 
            don't give you any information about what you should do next; as far as you 
            know, both the left and the right child are possible solutions. In many problems, 
            however, you may be able to eliminate children immediately, without recursion.</p>
          <p>Consider, for example, the problem of four-coloring a map. It is a theorem 
            of mathematics that any map on a plane, no matter how convoluted the countries 
            are, can be colored with at most four colors, so that no two countries that 
            share a border are the same color.</p>
          <p>To color a map, you choose a color for the first country, then a color for 
            the second country, and so on, until all countries are colored. There are two 
            ways to do this:</p>
        <ul>
       <li><b>Method 1. </b>Try each of the four possible colors, and recur. When you 
                  run out of countries, check whether you are at a goal node.</li>
        <li><b>Method 2. </b>Try only those colors that have not already been used for 
                  an adjacent country, and recur. If and when you run out of countries, you 
                  have successfully colored the map.</li>
        </ul>
        <p>Let's apply each of these two methods to the problem of coloring a checkerboard. 
                This should be easily solvable; after all, a checkerboard only needs two colors.
         </p>
         <p>Those appear pretty similar, and you might think they are equally good. However, 
            the timing information suggests otherwise:</p>
          <table align="center" border="1" cellpadding="4">
            <tbody><tr bgcolor="#cccccc"> 
              <td bgcolor="#ffffff">&nbsp;</td>
              <td>2 by 3 map</td>
              <td>3 by 3 map</td>
              <td>3 by 4 map</td>
            </tr>
            <tr>
              <td bgcolor="#cccccc">Method 1:</td>
              <td>60 ms.</td>
              <td>940 ms.</td>
              <td>60530 ms. (1 minute)</td>
            </tr>
            <tr>
              <td bgcolor="#cccccc">Method 2:</td>
              <td>0ms.</td>
              <td>0 ms.</td>
              <td>0 ms</td>
            </tr>
          </tbody></table>
          <p>The zeros in the above table indicate times too short to measure (less than 
            1 millisecond). Why this huge difference? Either of these methods <i>could</i> 
            have exponential growth. Eliminating a node automatically eliminates all of 
            its descendents, and this will often prevent exponential growth. Conversely, 
            by waiting to check until a leaf node is reached, exponential growth is practically 
            guaranteed. <i> <b>If there is any way to eliminate children (reduce the set 
            of choices), do so!</b></i></p>
          <p><font size="+1"><b><br />
            Debugging techniques</b></font></p>
          <p> Often our first try at a program doesn't work, and we need to debug it. Debuggers 
            are helpful, but sometimes we need to fall back on inserting print statements. 
            There are some simple tricks to making effective use of print statements. These 
            tricks can be applied to any program, but are especially useful when you are 
            trying to debug recursive routines.</p>
          <p><b>Trick #1: Indent when you print method entries and exits. </b>Often, the 
            best debugging technique is to print every method call and return (or at least 
            the most important ones). You probably want to print, for each method, what 
            parameters it came in with, and what value it leaves with. However, if you just 
            print a long list of these, it's hard to match up method exits with their corresponding 
            entries. Indenting to show the level of nesting can help.</p>
          <p><b>Trick #2: Use specialized print methods for debugging. </b>Don't clutter 
            up your actual code more than you must. Also, remember that code inserted for 
            debugging purposes can itself contain bugs, or (in the worst case) can affect 
            the results, so be very careful with it.</p>
          <p>Here's our debugging code. For this trivial program, there's almost more debugging 
            code than actual code, but in larger programs the proportions will be better.</p>
    


</body>
</html>
